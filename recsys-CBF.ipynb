{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uA2Pablwo8u-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import string\n",
    "\n",
    "import nltk \n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import movie_reviews, stopwords,wordnet\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from rake_nltk import Rake\n",
    "\n",
    "import numpy as np\n",
    "from numpy import arange,atleast_2d,argsort\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from surprise import Reader, Dataset, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpfulCutOffRatings = 20\n",
    "reviewDataPath = 'amazon/vsmall.csv'\n",
    "metadataPath = 'amazon/vsmall_metadata.json'\n",
    "topN = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeUnusedReviewInfo(rdata):\n",
    "    rdata = rdata.drop(['unixReviewTime','reviewTime','reviewerName'],axis=1)\n",
    "    return rdata\n",
    "    \n",
    "def createReviewerInfo(data):\n",
    "    reviewerInfo = data[['reviewerID', 'reviewerName']]\n",
    "    return reviewerInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createUserMovieMatrix(udata,mdata):\n",
    "    fullData = udata.merge(mdata, on='asin',how='outer')\n",
    "    userMovieMatrix = fullData.pivot_table(index='reviewerID', columns = 'asin',values = 'overall').reset_index().rename_axis(None, axis=1)\n",
    "    userMovieMatching = pd.crosstab(index = fullData['reviewerID'], columns=df['asin'],dropna = False)\n",
    "    userMovieMatrix = userMovieMatrix.replace(np.nan,0)\n",
    "    userMovieMatrix = userMovieMatrix.drop(['reviewerID'],axis = 1)\n",
    "    return userMovieMatrix, userMovieMatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify data into negative or positive\n",
    "def classifyBaseReviewRating(x):\n",
    "    if x > 2.5:\n",
    "        return \"positive\"\n",
    "    if x == 2.5:\n",
    "        return \"neutral\"\n",
    "    if x < 2.5:\n",
    "        return \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(r):\n",
    "    r = str(r)\n",
    "    if len(r) == 0:\n",
    "        return ''\n",
    "    if type(r) == float:\n",
    "        return ''\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordnetType(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def cleanReview(r):\n",
    "    r = str(r)\n",
    "    if len(r) == 0:\n",
    "        return ''\n",
    "    if type(r) == float:\n",
    "        return ''\n",
    "    r = r.lower()\n",
    "    #remove puncutation\n",
    "    r = [eachWord.strip(string.punctuation) for eachWord in r.split(\" \") ]\n",
    "    #remove numbers\n",
    "    r = [eachWord for eachWord in r if not any(l.isdigit() for l in eachWord)]\n",
    "    \n",
    "    #remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    r = [w for w in r if w not in stop]\n",
    "    \n",
    "    #remove words which are empty\n",
    "    r = [w for w in r if len(w) >0]\n",
    "    \n",
    "    #add pos_tags\n",
    "    pos_tags = pos_tag(r)\n",
    "    \n",
    "    #word lemmatize\n",
    "    r = [WordNetLemmatizer().lemmatize(t[0], getWordnetType(t[1])) for t in pos_tags]\n",
    "    \n",
    "    #remove useless words\n",
    "    r = [w for w in r if len(w) > 1]\n",
    "    \n",
    "    #recreate review\n",
    "    r = \" \".join(r)\n",
    "    return r\n",
    "\n",
    "# get compound score from VADER and append it as review rating\n",
    "def getSentimentScore(rdata):\n",
    "    sa = SentimentIntensityAnalyzer()\n",
    "    rdata[\"sentiments\"] = rdata[\"reviewText\"].apply(lambda x: sa.polarity_scores(x))\n",
    "    rdata = pd.concat([rdata.drop(['sentiments'], axis=1), rdata['sentiments'].apply(pd.Series)], axis=1)\n",
    "    rdata['helpful'] = rdata['helpful'].apply(lambda x: getHelpfulScore(x))\n",
    "    #compound score from VADER is from -1 to +1. Scaling it to 0 to 5 and multiplying it with helpfulness score\n",
    "    rdata['reviewRating'] = (1+(rdata['compound']+1)*2)\n",
    "#     rdata['reviewRating'] = (1+(rdata['compound']+1)*2) * rdata['helpful']\n",
    "    rdata = rdata.drop(['compound','pos','neg','neu'],axis = 1)\n",
    "    rdata = rdata.drop(['reviewText','helpful'],axis=1)\n",
    "    return rdata\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHelpfulScore(x):\n",
    "    if x == None:\n",
    "        return 1.0\n",
    "    x = literal_eval(x)\n",
    "    a = float(x[0])\n",
    "    b = float(x[1])\n",
    "\n",
    "    if b != 0 and a + b > helpfulCutOffRatings-1:\n",
    "        return a / (a + b)\n",
    "    else:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSentimentScoreOnReviews(rdata):\n",
    "    reviewerInfo = createReviewerInfo(rdata)\n",
    "    rdata = removeUnusedReviewInfo(rdata)\n",
    "    rdata[\"reviewType\"] = rdata[\"overall\"].apply(classifyBaseReviewRating)\n",
    "    rdata['reviewText'] = rdata['reviewText'] + rdata['summary']\n",
    "    rdata = rdata.drop(['summary'],axis = 1)\n",
    "    rdata['reviewText'] = rdata['reviewText'].apply(cleanData)    \n",
    "    rdata['reviewText'] = rdata['reviewText'].apply(lambda x:cleanReview(x))\n",
    "    rdata = getSentimentScore(rdata)\n",
    "    return rdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovieData(path):\n",
    "    return pd.read_json(path,lines=True,typ='frame')\n",
    "\n",
    "def preProcessMovieData(moviedata):\n",
    "    moviedata.sort_values(\"asin\",inplace=True)\n",
    "    moviedata.drop_duplicates(subset='asin',keep=False,inplace = True)\n",
    "    moviedata = moviedata.reset_index(drop=True)\n",
    "    moviedata = moviedata.drop(['rank','main_cat','image','also_buy','also_view','price','details','feature','date','tech1'],axis = 1,errors='ignore')\n",
    "    return moviedata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineSimilarity(moviedata):\n",
    "    count = CountVectorizer()\n",
    "    count_matrix = count.fit_transform(moviedata['cleanText'])\n",
    "    # generating the cosine similarity matrix\n",
    "    cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "    return cosine_sim\n",
    "\n",
    "# def getMovieSimilarityFromPlot(moviedata):\n",
    "#     # initializing the new column\n",
    "#     moviedata['impWords'] = ''\n",
    "#     moviedata['cleanText'] = ''\n",
    "#     for index, movie in moviedata.iterrows():\n",
    "#         tot = ''\n",
    "#         description = movie['description']\n",
    "#         if description != None:\n",
    "#             if type(description) != float:\n",
    "#                 if len(description) != 0:\n",
    "#                     for i in description:\n",
    "#                         if type(i) != str:\n",
    "#                             print(description)\n",
    "#                         tot = tot + i\n",
    "\n",
    "#         #remove \"Movies & TV\", \"Genre for Featured Categories\", \"Movies\", \"Independently Distributed\", \"All Titles\", \"All\", \"4-for-3 DVD\", \n",
    "#         ignoreWords = [\"Movies & TV\", \"Genre for Featured Categories\", \"Movies\", \"Independently Distributed\", \"All Titles\", \"All\", \"4-for-3 DVD\"]\n",
    "#         category = movie['category']\n",
    "#         if category != None:\n",
    "#             if type(category) != float:\n",
    "#                 for w in category:\n",
    "#                     if w not in ignoreWords:\n",
    "#                         tot = tot+w\n",
    "#         brand = movie['brand']\n",
    "#         if brand != None:\n",
    "#             if type(brand) != float:\n",
    "#                 tot = tot + i\n",
    "#         r = Rake()\n",
    "#         r.extract_keywords_from_text(tot)\n",
    "#         # getting the dictionary whith key words as keys and their scores as values\n",
    "#         key_words_dict_scores = r.get_word_degrees()\n",
    "\n",
    "#         # assigning the key words to the new column for the corresponding movie\n",
    "#         movie['impWords'] = list(key_words_dict_scores.keys())\n",
    "#         movie['cleanText'] = \" \".join(map(str,movie['impWords']))\n",
    "#     moviedata = moviedata.drop(['category','brand','description','impWords'],axis = 1)\n",
    "#     cosine_sim =  getCosineSimilarity(moviedata)\n",
    "#     moviedata = moviedata.drop(['cleanText'],axis = 1)\n",
    "#     return cosine_sim, moviedata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovieAvgRating(moviedata,rdataf):\n",
    "    movieAvgRating = rdataf.groupby('asin')['overall'].agg(['mean', 'median', 'size'])\n",
    "    movieAvgRating.columns = ['rating_mean', 'rating_median', 'num_ratings']\n",
    "    return movieAvgRating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top3_recommendations(predictions, topN = 3):\n",
    "     \n",
    "    top_recs = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_recs[uid].append((iid, est))\n",
    "     \n",
    "    for uid, user_ratings in top_recs.items():\n",
    "        user_ratings.sort(key = lambda x: x[1], reverse = True)\n",
    "        top_recs[uid] = user_ratings[:topN]\n",
    "     \n",
    "    return top_recs\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictionFromMovieContent(moviedata, rdata, testSplit):\n",
    "    moviedata = preProcessMovieData(moviedata)\n",
    "    # craete cosine similarity matrix\n",
    "    cosine_sim, moviedata = getMovieSimilarityFromPlot(moviedata)\n",
    "    rdata, testdata = train_test_split(rdata, test_size=testSplit)\n",
    "#     userMovieMatrix = createUserMovieMatrix(rdata,moviedata)\n",
    "    rdata = rdata.merge(moviedata, on='asin',how='left')\n",
    "    movieAvgRating = getMovieAvgRating(moviedata,rdata)\n",
    "    movieAvgRating.columns = ['rating_mean', 'rating_median', 'num_ratings']\n",
    "    moviedata = moviedata.merge(movieAvgRating, on='asin',how='left')\n",
    "    \n",
    "    predictions = getUserRatingPredictionFromMovieContent(cosine_sim, rdata, testdata, moviedata)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUserRatingPredictionFromMovieContent(cosine_sim, rdata, testdata, moviedata):\n",
    "    userMovieMatrix,userMovieMatching = createUserMovieMatrix(rdata, moviedata)\n",
    "    sumUserMovieWeight = np.dot(userMovieMatrix, cosine_sim)\n",
    "    sumSimFoRM2M = np.dot(userMovieMatching, cosine_sim)\n",
    "    userMoviePredict = sumUserMovieWeight/sumSimFoRM2M\n",
    "    \n",
    "    predictions = dict()\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on field in and type\n",
    "def getSurpriseRatingPrediction(data, ratingCol, testSplit, algo, userBased):\n",
    "    ratings_dict = {'itemID': list(data.asin),\n",
    "                'userID': list(data.reviewerID),\n",
    "                'rating': list(data[ratingCol])}\n",
    "    df = pd.DataFrame(ratings_dict)\n",
    "    \n",
    "    # A reader is still needed but only the rating_scale param is required.\n",
    "    # The Reader class is used to parse a file containing ratings.\n",
    "    reader = Reader(rating_scale=(0.5, 5.0))\n",
    "    # The columns must correspond to user id, item id and ratings (in that order).\n",
    "    data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
    "    trainset, testset = train_test_split(data, test_size=testSplit)\n",
    "    if algo == 'svd':\n",
    "        algo = SVD()\n",
    "    elif algo == 'knn':\n",
    "        sim_options = {'name': 'cosine',\n",
    "               'user_based': userBased\n",
    "               }\n",
    "        algo = algo = KNNBaseline(sim_options=sim_options)\n",
    "    algo.fit(trainset)\n",
    "    print('mean',trainset.global_mean)\n",
    "    predictions = algo.test(testset)\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(rdata, moviedata, testSplit, topN):\n",
    "    # get SVD predictions\n",
    "    svdPredictions = getSurpriseRatingPrediction(rdata, 'overall', testSplit, 'svd', False )\n",
    "    \n",
    "    #get Knn user based predictions based on ratings\n",
    "    userBasedKNNPredictions = getSurpriseRatingPrediction(rdata, 'overall', testSplit, 'knn', True)\n",
    "    \n",
    "    #get Knn movie based predictions based on ratings\n",
    "    ratingBasedKNNPredictions = getSurpriseRatingPrediction(rdata, 'overall', testSplit, 'knn', False)\n",
    "    \n",
    "    #get Knn movie based predictions based on reviews\n",
    "    rdata = generateSentimentScoreOnReviews(rdata)\n",
    "    reviewBasedKNNPredictions = getSurpriseRatingPrediction(rdata, 'reviewRating', testSplit, 'knn', False)\n",
    "    \n",
    "    #get content based predictions\n",
    "    contentBasedPredictions = getPredictionFromMovieContent(moviedata, rdata, testSplit)\n",
    "    \n",
    "    topNRec = getFinalRec(svdPredictions, userBasedKNNPredictions,\n",
    "                                           ratingBasedKNNPredictions, reviewBasedKNNPredictions,\n",
    "                                          contentBasedPredictions, topN)\n",
    "    return topNRec\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the predictions score by weighted average\n",
    "def combinePredictions(svdPredictions, userBasedKNNPredictions,\n",
    "                                           ratingBasedKNNPredictions, reviewBasedKNNPredictions,\n",
    "                                          contentBasedPredictions):\n",
    "    svdPredictionsNew = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in svdPredictions:\n",
    "            svdPredictionsNew[uid].append((iid, est))\n",
    "    \n",
    "    \n",
    "    userBasedKNNPredictionsNew = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in userBasedKNNPredictions:\n",
    "            userBasedKNNPredictionsNew[uid].append((iid, est))\n",
    "            \n",
    "    \n",
    "    ratingBasedKNNPredictionsNew = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in ratingBasedKNNPredictions:\n",
    "            ratingBasedKNNPredictionsNew[uid].append((iid, est))\n",
    "    \n",
    "    \n",
    "    reviewBasedKNNPredictionsNew = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in reviewBasedKNNPredictions:\n",
    "            reviewBasedKNNPredictionsNew[uid].append((iid, est))\n",
    "    \n",
    "    # contentBasedPredictions is already of the form like above\n",
    "    # TODO: add scores of different methods and recommend\n",
    "    \n",
    "    return top_recs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFinalRec(svdPredictions, userBasedKNNPredictions,\n",
    "                                           ratingBasedKNNPredictions, reviewBasedKNNPredictions,\n",
    "                                          contentBasedPredictions, topN):\n",
    "    \n",
    "    predictions = combinePredictions(svdPredictions, userBasedKNNPredictions,\n",
    "                                           ratingBasedKNNPredictions, reviewBasedKNNPredictions,\n",
    "                                          contentBasedPredictions)\n",
    "    \n",
    "    for uid, user_ratings in top_recs.items():\n",
    "        user_ratings.sort(key = lambda x: x[1], reverse = True)\n",
    "        top_recs[uid] = user_ratings[:topN]\n",
    "    return top_recs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2mCosim = pd.DataFrame(cosine_sim)\n",
    "# indexWithMovieId = moviedata['asin']\n",
    "# m2mCosim.columns = [str(indexWithMovieId[int(col)]) for col in m2mCosim.columns]\n",
    "# m2mCosim.index = [indexWithMovieId[idx] for idx in m2mCosim.index]\n",
    "# # m2mCosim.iloc[0].sort_values(ascending=False)[:10]\n",
    "# userRatings = rdataf[rdataf.reviewerID == 'A1GHUN5HXMHZ89']\n",
    "# userRatings.head(2)\n",
    "# userDataWithScore = moviedata.reset_index().merge(userRatings, on='asin')\n",
    "\n",
    "# userDataWithScore['weight'] = userDataWithScore['overall']/5\n",
    "# # df_user_data_with_tags['weight'].values\n",
    "# # df_user_data_with_tags\n",
    "# user_profile = np.dot(count_matrix[userDataWithScore['index'].values].toarray().T, userDataWithScore['weight'].values)\n",
    "# C = cosine_similarity(atleast_2d(user_profile), count_matrix)\n",
    "# R = argsort(C)[:, ::-1]\n",
    "# recommendations = [i for i in R[0] if i not in userDataWithScore['index'].values]\n",
    "# rdataf['asin'][recommendations].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata = pd.read_csv('amazon/vsmall.csv', names=['reviewerID','asin','reviewerName','helpful','reviewText','overall','summary','unixReviewTime','reviewTime'], skiprows=1, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata = rdata.drop(['index'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviedata = pd.read_json('amazon/vsmall_metadata.json',lines=True,typ='frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>asin</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rise and Swine (Good Eats Vol. 7)</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>corn dogs macerated strawberries good eats vol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My Fair Pastry (Good Eats Vol. 9)</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>southern biscuits salmon turnovers fruit tart ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everyday Italian (with Giada de Laurentiis), V...</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>christmas dinner party birthday giada de laure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barefoot Contessa (with Ina Garten), Entertain...</td>\n",
       "      <td>0000143588</td>\n",
       "      <td>prepare scrumptious dishes delicious offerings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Understanding Seizures and Epilepsy</td>\n",
       "      <td>0000695009</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>The Deep End of the Ocean VHS</td>\n",
       "      <td>0767819519</td>\n",
       "      <td>careful certainly credible part 3 expect every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Pal Joey</td>\n",
       "      <td>0767821807</td>\n",
       "      <td>charming nightclub singer title character danc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Hard Times</td>\n",
       "      <td>0767824555</td>\n",
       "      <td>break subject directed violence spare existent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Monty Python and the Holy Grail</td>\n",
       "      <td>0767824571</td>\n",
       "      <td>short list almost certainly dead kind pythons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Iron Eagle</td>\n",
       "      <td>0767827686</td>\n",
       "      <td>negotiate father taken prisoner tough jr gosse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title        asin  \\\n",
       "0                    Rise and Swine (Good Eats Vol. 7)  0000143502   \n",
       "1                    My Fair Pastry (Good Eats Vol. 9)  0000143529   \n",
       "2    Everyday Italian (with Giada de Laurentiis), V...  0000143561   \n",
       "3    Barefoot Contessa (with Ina Garten), Entertain...  0000143588   \n",
       "4                  Understanding Seizures and Epilepsy  0000695009   \n",
       "..                                                 ...         ...   \n",
       "277                      The Deep End of the Ocean VHS  0767819519   \n",
       "278                                           Pal Joey  0767821807   \n",
       "279                                         Hard Times  0767824555   \n",
       "280                    Monty Python and the Holy Grail  0767824571   \n",
       "281                                         Iron Eagle  0767827686   \n",
       "\n",
       "                                             cleanText  \n",
       "0    corn dogs macerated strawberries good eats vol...  \n",
       "1    southern biscuits salmon turnovers fruit tart ...  \n",
       "2    christmas dinner party birthday giada de laure...  \n",
       "3    prepare scrumptious dishes delicious offerings...  \n",
       "4                                                       \n",
       "..                                                 ...  \n",
       "277  careful certainly credible part 3 expect every...  \n",
       "278  charming nightclub singer title character danc...  \n",
       "279  break subject directed violence spare existent...  \n",
       "280  short list almost certainly dead kind pythons ...  \n",
       "281  negotiate father taken prisoner tough jr gosse...  \n",
       "\n",
       "[282 rows x 3 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviedata = preProcessMovieData(moviedata)\n",
    "moviedata = getMovieSimilarityFromPlot(moviedata)\n",
    "moviedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_idf = TfidfVectorizer()\n",
    "moviesTFIDFdescribed = tf_idf.fit_transform(moviedata.cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# userAsinRating = rdata[['reviewerID','asin','overall']]\n",
    "# userAsinRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "userAsinRating = rdata[['reviewerID','asin','overall']]\n",
    "userMoviePlot = pd.merge(userAsinRating,moviedata,on='asin',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "userMoviePlot = userMoviePlot.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineMovieText(text):\n",
    "    text_as_str = ' '.join(set(text))\n",
    "    return text_as_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "userMoviePlot = userMoviePlot.groupby('reviewerID')['cleanText'].agg(combineMovieText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "userMoviePlot.name = 'cleanText'\n",
    "userMoviePlot = userMoviePlot.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A101FH66IRVOEQ</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A102RDJLOHWS0W</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1033RWNZWEMR5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A103EXN5Q7HX6Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A106016KSI0YQ</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>AZT60HLHFL0V0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>AZWJ4ZNG2Z5GO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>AZXGPM8EKSHE9</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>AZXHK8IO25FL6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>AZZ2DEE2NTIM7</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1881 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          reviewerID cleanText\n",
       "0     A101FH66IRVOEQ          \n",
       "1     A102RDJLOHWS0W          \n",
       "2     A1033RWNZWEMR5          \n",
       "3     A103EXN5Q7HX6Z          \n",
       "4      A106016KSI0YQ          \n",
       "...              ...       ...\n",
       "1876   AZT60HLHFL0V0          \n",
       "1877   AZWJ4ZNG2Z5GO          \n",
       "1878   AZXGPM8EKSHE9          \n",
       "1879   AZXHK8IO25FL6          \n",
       "1880   AZZ2DEE2NTIM7          \n",
       "\n",
       "[1881 rows x 2 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userMoviePlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A22XGVAAD5WCNS</td>\n",
       "      <td>6304217420</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2Z5RFU4DH3T0G</td>\n",
       "      <td>B00005JNBQ</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR9OIGY3T6EU7</td>\n",
       "      <td>B000ZECQ08</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEVIYGYO0FEOM</td>\n",
       "      <td>6300270351</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AQUNXYDV20Z9R</td>\n",
       "      <td>630447976X</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>A8IZXBE7J6RNJ</td>\n",
       "      <td>6302642248</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>A1RKS0O04U3GY3</td>\n",
       "      <td>B00023P4HY</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>A3RICVFW2YD1LZ</td>\n",
       "      <td>B000FILVFA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>ANCOMAI0I7LVG</td>\n",
       "      <td>B0062NAWH0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>A3VK8IGT37Y94I</td>\n",
       "      <td>6300215849</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          reviewerID        asin  overall\n",
       "0     A22XGVAAD5WCNS  6304217420        5\n",
       "1     A2Z5RFU4DH3T0G  B00005JNBQ        5\n",
       "2      AR9OIGY3T6EU7  B000ZECQ08        4\n",
       "3      AEVIYGYO0FEOM  6300270351        4\n",
       "4      AQUNXYDV20Z9R  630447976X        5\n",
       "...              ...         ...      ...\n",
       "1995   A8IZXBE7J6RNJ  6302642248        5\n",
       "1996  A1RKS0O04U3GY3  B00023P4HY        4\n",
       "1997  A3RICVFW2YD1LZ  B000FILVFA        2\n",
       "1998   ANCOMAI0I7LVG  B0062NAWH0        3\n",
       "1999  A3VK8IGT37Y94I  6300215849        4\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userAsinRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A22XGVAAD5WCNS</td>\n",
       "      <td>6304217420</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A2Z5RFU4DH3T0G</td>\n",
       "      <td>B00005JNBQ</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AR9OIGY3T6EU7</td>\n",
       "      <td>B000ZECQ08</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AEVIYGYO0FEOM</td>\n",
       "      <td>6300270351</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AQUNXYDV20Z9R</td>\n",
       "      <td>630447976X</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1994</td>\n",
       "      <td>A8P076YJHIMBN</td>\n",
       "      <td>B0002NRRQU</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1995</td>\n",
       "      <td>A8IZXBE7J6RNJ</td>\n",
       "      <td>6302642248</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1996</td>\n",
       "      <td>A1RKS0O04U3GY3</td>\n",
       "      <td>B00023P4HY</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1997</td>\n",
       "      <td>A3RICVFW2YD1LZ</td>\n",
       "      <td>B000FILVFA</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>A3VK8IGT37Y94I</td>\n",
       "      <td>6300215849</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      reviewerID        asin  overall cleanText\n",
       "0         0  A22XGVAAD5WCNS  6304217420        5          \n",
       "1         1  A2Z5RFU4DH3T0G  B00005JNBQ        5          \n",
       "2         2   AR9OIGY3T6EU7  B000ZECQ08        4          \n",
       "3         3   AEVIYGYO0FEOM  6300270351        4          \n",
       "4         4   AQUNXYDV20Z9R  630447976X        5          \n",
       "...     ...             ...         ...      ...       ...\n",
       "1995   1994   A8P076YJHIMBN  B0002NRRQU        4          \n",
       "1996   1995   A8IZXBE7J6RNJ  6302642248        5          \n",
       "1997   1996  A1RKS0O04U3GY3  B00023P4HY        4          \n",
       "1998   1997  A3RICVFW2YD1LZ  B000FILVFA        2          \n",
       "1999   1999  A3VK8IGT37Y94I  6300215849        4          \n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# userAsinRatingPlot = pd.merge(userAsinRating,userMoviePlot, on='reviewerID',how='left')\n",
    "userDataWithTextP =  userAsinRating.reset_index().merge(userMoviePlot,on='reviewerID')\n",
    "userDataWithTextP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A22XGVAAD5WCNS</td>\n",
       "      <td>6304217420</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A2Z5RFU4DH3T0G</td>\n",
       "      <td>B00005JNBQ</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AR9OIGY3T6EU7</td>\n",
       "      <td>B000ZECQ08</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AEVIYGYO0FEOM</td>\n",
       "      <td>6300270351</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AQUNXYDV20Z9R</td>\n",
       "      <td>630447976X</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1994</td>\n",
       "      <td>A8P076YJHIMBN</td>\n",
       "      <td>B0002NRRQU</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1995</td>\n",
       "      <td>A8IZXBE7J6RNJ</td>\n",
       "      <td>6302642248</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1996</td>\n",
       "      <td>A1RKS0O04U3GY3</td>\n",
       "      <td>B00023P4HY</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1997</td>\n",
       "      <td>A3RICVFW2YD1LZ</td>\n",
       "      <td>B000FILVFA</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>A3VK8IGT37Y94I</td>\n",
       "      <td>6300215849</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      reviewerID        asin  overall cleanText  weight\n",
       "0         0  A22XGVAAD5WCNS  6304217420        5               1.0\n",
       "1         1  A2Z5RFU4DH3T0G  B00005JNBQ        5               1.0\n",
       "2         2   AR9OIGY3T6EU7  B000ZECQ08        4               0.8\n",
       "3         3   AEVIYGYO0FEOM  6300270351        4               0.8\n",
       "4         4   AQUNXYDV20Z9R  630447976X        5               1.0\n",
       "...     ...             ...         ...      ...       ...     ...\n",
       "1995   1994   A8P076YJHIMBN  B0002NRRQU        4               0.8\n",
       "1996   1995   A8IZXBE7J6RNJ  6302642248        5               1.0\n",
       "1997   1996  A1RKS0O04U3GY3  B00023P4HY        4               0.8\n",
       "1998   1997  A3RICVFW2YD1LZ  B000FILVFA        2               0.4\n",
       "1999   1999  A3VK8IGT37Y94I  6300215849        4               0.8\n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userDataWithTextP['weight'] = userDataWithTextP['overall']/5\n",
    "userDataWithTextP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index (1999) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-0b4a04dc5f3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmoviesTFIDFdescribed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserDataWithTextP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Dispatch to specialized methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m_validate_indices\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mrow\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m_asindices\u001b[0;34m(self, idx, length)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mmax_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_indx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index (%d) out of range'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmax_indx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mmin_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index (1999) out of range"
     ]
    }
   ],
   "source": [
    "# moviesTFIDFdescribed[userDataWithTextP['index'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile = np.dot(df_movies_tf_idf_described[df_user_data_with_tags['index'].values].toarray().T, df_user_data_with_tags['weight'].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovieSimilarityFromPlot(moviedata):\n",
    "    # initializing the new column\n",
    "    moviedata['impWords'] = ''\n",
    "    moviedata['cleanText'] = ''\n",
    "    for index, movie in moviedata.iterrows():\n",
    "        tot = ''\n",
    "        description = movie['description']\n",
    "        if description != None:\n",
    "            if type(description) != float:\n",
    "                if len(description) != 0:\n",
    "                    for i in description:\n",
    "                        if type(i) != str:\n",
    "                            print(description)\n",
    "                        tot = tot + i\n",
    "\n",
    "        #remove \"Movies & TV\", \"Genre for Featured Categories\", \"Movies\", \"Independently Distributed\", \"All Titles\", \"All\", \"4-for-3 DVD\", \n",
    "        ignoreWords = [\"Movies & TV\", \"Genre for Featured Categories\", \"Movies\", \"Independently Distributed\", \"All Titles\", \"All\", \"4-for-3 DVD\"]\n",
    "        category = movie['category']\n",
    "        if category != None:\n",
    "            if type(category) != float:\n",
    "                for w in category:\n",
    "                    if w not in ignoreWords:\n",
    "                        tot = tot+w\n",
    "        brand = movie['brand']\n",
    "        if brand != None:\n",
    "            if type(brand) != float:\n",
    "                tot = tot + i\n",
    "        r = Rake()\n",
    "        r.extract_keywords_from_text(tot)\n",
    "        # getting the dictionary whith key words as keys and their scores as values\n",
    "        key_words_dict_scores = r.get_word_degrees()\n",
    "\n",
    "        # assigning the key words to the new column for the corresponding movie\n",
    "        movie['impWords'] = list(key_words_dict_scores.keys())\n",
    "        movie['cleanText'] = \" \".join(map(str,movie['impWords']))\n",
    "    moviedata = moviedata.drop(['category','brand','description','impWords'],axis = 1)\n",
    "#     cosine_sim =  getCosineSimilarity(moviedata)\n",
    "#     moviedata = moviedata.drop(['cleanText'],axis = 1)\n",
    "    return moviedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictionFromMovieContent(moviedata, rdata, testSplit):\n",
    "    moviedata = preProcessMovieData(moviedata)\n",
    "    # craete cosine similarity matrix\n",
    "    cosine_sim, moviedata = getMovieSimilarityFromPlot(moviedata)\n",
    "    rdata, testdata = train_test_split(rdata, test_size=testSplit)\n",
    "#     userMovieMatrix = createUserMovieMatrix(rdata,moviedata)\n",
    "    rdata = rdata.merge(moviedata, on='asin',how='left')\n",
    "    movieAvgRating = getMovieAvgRating(moviedata,rdata)\n",
    "    movieAvgRating.columns = ['rating_mean', 'rating_median', 'num_ratings']\n",
    "    moviedata = moviedata.merge(movieAvgRating, on='asin',how='left')\n",
    "    \n",
    "    predictions = getUserRatingPredictionFromMovieContent(cosine_sim, rdata, testdata, moviedata)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# craete cosine similarity matrix\n",
    "# cosine_sim, moviedata = getMovieSimilarityFromPlot(moviedata)\n",
    "# rdata, testdata = train_test_split(rdata, test_size=testSplit)\n",
    "# #     userMovieMatrix = createUserMovieMatrix(rdata,moviedata)\n",
    "# rdata = rdata.merge(moviedata, on='asin',how='left')\n",
    "# movieAvgRating = getMovieAvgRating(moviedata,rdata)\n",
    "# movieAvgRating.columns = ['rating_mean', 'rating_median', 'num_ratings']\n",
    "# moviedata = moviedata.merge(movieAvgRating, on='asin',how='left')\n",
    "\n",
    "# predictions = getUserRatingPredictionFromMovieContent(cosine_sim, rdata, testdata, moviedata)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "svd.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
